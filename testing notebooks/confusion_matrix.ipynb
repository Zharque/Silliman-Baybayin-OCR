{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47d7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 100 image(s) per class for evaluation...\n",
      "Total images selected for evaluation: 4500\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model loaded from vgg16_model.h5\n",
      "ResNet model loaded from resnet18_model.pth\n",
      "Loading saved ViT model object...\n",
      "ViT model loaded from vit_model.pth\n",
      "Generating predictions and updating confusion matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Images: 100%|██████████| 4500/4500 [22:57<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving confusion matrices to subfolder: confusionMatrix\n",
      "Saved confusion matrix to confusionMatrix\\confusion_VGG16.csv\n",
      "Saved confusion matrix to confusionMatrix\\confusion_ResNet.csv\n",
      "Saved confusion matrix to confusionMatrix\\confusion_ViT.csv\n",
      "Saved confusion matrix to confusionMatrix\\confusion_ConfidenceEnsemble.csv\n",
      "Saved confusion matrix to confusionMatrix\\confusion_ConfidenceEnsemble_NoViT.csv\n",
      "Saved confusion matrix to confusionMatrix\\confusion_EnsembleA.csv\n",
      "Saved confusion matrix to confusionMatrix\\confusion_EnsembleB.csv\n",
      "Saved confusion matrix to confusionMatrix\\confusion_EnsembleC.csv\n",
      "Saved confusion matrix to confusionMatrix\\confusion_EnsembleD.csv\n",
      "Saved confusion matrix to confusionMatrix\\confusion_EnsembleE.csv\n",
      "\n",
      "Script finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "import random\n",
    "from tensorflow.keras.models import load_model\n",
    "try:\n",
    "    import timm\n",
    "except ImportError:\n",
    "    timm = None\n",
    "from torchvision import transforms\n",
    "\n",
    "# ======== CONFIGURABLE SETTINGS ========\n",
    "DATASET_DIR = \"dataset\"\n",
    "TEST_DIR = \"unprocessed_dataset\"\n",
    "IMAGES_PER_CLASS = 100 # Adjust as needed for confusion matrix generation\n",
    "OUTPUT_SUBFOLDER = \"confusionMatrix\" # Define the subfolder for saving CSVs\n",
    "# Define Model Weights for different Ensembles\n",
    "ENSEMBLE_WEIGHTS = {\n",
    "    'EnsembleA': {'VGG16': 0.4, 'ResNet': 0.4, 'ViT': 0.2}, # tie break A\n",
    "    'EnsembleB': {'VGG16': 0.34, 'ResNet': 0.34, 'ViT': 0.32}, # tie break B\n",
    "    'EnsembleC': {'VGG16': 0.5, 'ResNet': 0.5, 'ViT': 0.0}, # no ViT\n",
    "    'EnsembleD': {'VGG16': 0.0, 'ResNet': 0.5, 'ViT': 0.5}, # no VGG16\n",
    "    'EnsembleE': {'VGG16': 0.5, 'ResNet': 0.0, 'ViT': 0.5} # no ResNet\n",
    "}\n",
    "# =======================================\n",
    "\n",
    "valid_exts = ('.png', '.jpg', '.jpeg', '.bmp', '.gif')\n",
    "\n",
    "# Preprocessing function for OCR-like binarization\n",
    "def ocr_preprocessing(image, block_size=31, C=20):\n",
    "    gray = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "    gray_uint8 = (gray * 255).astype(np.uint8)\n",
    "    binarized = cv2.adaptiveThreshold(gray_uint8, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, C)\n",
    "    return np.stack([binarized/255.0]*3, axis=-1)\n",
    "\n",
    "# Binarize image function using TensorFlow/Keras\n",
    "def binarize_image(image_path, target_size=(56,56)):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size)\n",
    "    arr = tf.keras.preprocessing.image.img_to_array(img)/255.0\n",
    "    bin_arr = ocr_preprocessing(arr)\n",
    "    return Image.fromarray((bin_arr*255).astype(np.uint8))\n",
    "\n",
    "# Function to get sorted class names from directory structure\n",
    "def get_class_names(train_dir):\n",
    "    # Check if the directory exists before listing\n",
    "    if not os.path.isdir(train_dir):\n",
    "        print(f\"Warning: Training directory '{train_dir}' not found for deriving class names.\")\n",
    "        return []\n",
    "    return sorted([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])\n",
    "\n",
    "# Predict top N classes using a Keras model\n",
    "def predict_top_n_keras(model, image, class_names, top_n=3):\n",
    "    # Basic check if model expects classes and class_names list is available\n",
    "    if not class_names and hasattr(model, 'output_shape') and model.output_shape[-1] > 0:\n",
    "         print(\"Warning: Keras model prediction called without class names derived.\")\n",
    "    try:\n",
    "        preds = model.predict(np.expand_dims(np.array(image)/255.0, axis=0), verbose=0)[0]\n",
    "        top_indices = np.argsort(preds)[-top_n:][::-1]\n",
    "        results = []\n",
    "        for i in top_indices:\n",
    "             # Attempt to map index to name, fallback to index string if needed\n",
    "             if class_names and i < len(class_names):\n",
    "                 results.append((class_names[i], preds[i]))\n",
    "             else:\n",
    "                  results.append((f\"Index_{i}\", preds[i]))\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Keras prediction: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Predict top N classes using a PyTorch model\n",
    "def predict_top_n_torch(model, transform, image, class_names, device, top_n=3):\n",
    "    # Basic check for class names\n",
    "    if not class_names:\n",
    "        print(\"Warning: PyTorch model prediction called without class names derived.\")\n",
    "    try:\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            logits = output.logits if hasattr(output, \"logits\") else output\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=1)[0]\n",
    "        top_probs, top_indices = torch.topk(probabilities, top_n)\n",
    "        top_n_preds = []\n",
    "        for i in range(top_n):\n",
    "            cls_idx = top_indices[i].item()\n",
    "            prob = top_probs[i].item()\n",
    "            # Attempt to map index to name, fallback to index string if needed\n",
    "            if class_names and cls_idx < len(class_names):\n",
    "                 top_n_preds.append((class_names[cls_idx], prob))\n",
    "            else:\n",
    "                 top_n_preds.append((f\"Index_{cls_idx}\", prob))\n",
    "        return top_n_preds\n",
    "    except Exception as e:\n",
    "        print(f\"Error during PyTorch prediction: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Define a ResNet18 model adapted for binary (1-channel) input\n",
    "class BinaryResNet18(ResNet):\n",
    "    def __init__(self, num_classes=45): # Default classes if not provided\n",
    "        super().__init__(BasicBlock, [2,2,2,2], num_classes=num_classes)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Evaluate models and generate confusion matrices\n",
    "def evaluate_models_confusion_matrix():\n",
    "    # Derive class names and count\n",
    "    train_dir = os.path.join(DATASET_DIR, \"train\")\n",
    "    class_names = get_class_names(train_dir)\n",
    "    num_classes = len(class_names)\n",
    "    if num_classes == 0:\n",
    "        # Changed from warning to error as num_classes=0 will likely break model loading/evaluation\n",
    "        raise ValueError(f\"No class subdirectories found in '{train_dir}'. Cannot proceed without classes.\")\n",
    "\n",
    "    # Collect image paths from the test directory\n",
    "    image_paths_by_class = defaultdict(list)\n",
    "    if not os.path.exists(TEST_DIR) or not os.path.isdir(TEST_DIR):\n",
    "        raise FileNotFoundError(f\"Test directory '{TEST_DIR}' not found.\")\n",
    "    for root, _, files in os.walk(TEST_DIR):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(valid_exts):\n",
    "                class_name = os.path.basename(root)\n",
    "                if class_name in class_names: # Only include images from known classes\n",
    "                    image_paths_by_class[class_name].append(os.path.join(root, file))\n",
    "\n",
    "    # Select images for evaluation\n",
    "    selected_paths = []\n",
    "    selected_labels = []\n",
    "    print(f\"Selecting {IMAGES_PER_CLASS} image(s) per class for evaluation...\")\n",
    "    for cls in class_names:\n",
    "        available_images = image_paths_by_class[cls]\n",
    "        if len(available_images) < IMAGES_PER_CLASS:\n",
    "            print(f\"Warning: Class {cls} has insufficient test images ({len(available_images)}) - needs at least {IMAGES_PER_CLASS}. Using all available.\")\n",
    "            if not available_images:\n",
    "                 print(f\"Warning: Class {cls} has no images in {TEST_DIR}. Skipping this class.\")\n",
    "                 continue\n",
    "            num_to_sample = len(available_images)\n",
    "        else:\n",
    "            num_to_sample = IMAGES_PER_CLASS\n",
    "\n",
    "        selected_paths.extend(random.sample(available_images, num_to_sample))\n",
    "        selected_labels.extend([cls] * num_to_sample)\n",
    "\n",
    "    if not selected_paths:\n",
    "        print(\"No images selected for evaluation. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Total images selected for evaluation: {len(selected_paths)}\")\n",
    "\n",
    "    # Set up device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load Keras model (VGG16)\n",
    "    keras_model_path = \"vgg16_model.h5\"\n",
    "    keras_model = None\n",
    "    if os.path.exists(keras_model_path):\n",
    "        try:\n",
    "            keras_model = load_model(keras_model_path)\n",
    "            # Basic validation if model output matches num_classes\n",
    "            if keras_model.output_shape[-1] != num_classes:\n",
    "                 print(f\"Warning: Keras model output units ({keras_model.output_shape[-1]}) mismatch dataset classes ({num_classes}).\")\n",
    "            print(f\"Keras model loaded from {keras_model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Keras model from {keras_model_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Keras model file not found: {keras_model_path}\")\n",
    "\n",
    "    # Load PyTorch model (ResNet18)\n",
    "    resnet_model_path = \"resnet18_model.pth\"\n",
    "    resnet_model = None\n",
    "    if os.path.exists(resnet_model_path):\n",
    "        try:\n",
    "            resnet_model = BinaryResNet18(num_classes=num_classes).to(device) # Use derived num_classes\n",
    "            checkpoint = torch.load(resnet_model_path, map_location=device)\n",
    "            if isinstance(checkpoint, dict) and \"model_state_dict\" in checkpoint:\n",
    "                state_dict = checkpoint[\"model_state_dict\"]\n",
    "            elif isinstance(checkpoint, dict):\n",
    "                 state_dict = checkpoint\n",
    "            else:\n",
    "                 resnet_model = checkpoint\n",
    "                 state_dict = None\n",
    "\n",
    "            if state_dict:\n",
    "                # Clean keys\n",
    "                new_state_dict = {\n",
    "                    k[len(\"model.\"):] if k.startswith(\"model.\") else k: v\n",
    "                    for k, v in state_dict.items()\n",
    "                }\n",
    "                # Load state_dict, consider strict=False if necessary but be cautious\n",
    "                try:\n",
    "                     resnet_model.load_state_dict(new_state_dict, strict=True)\n",
    "                except RuntimeError as e:\n",
    "                     print(f\"Error loading ResNet state_dict (likely mismatch): {e}. Trying strict=False.\")\n",
    "                     try:\n",
    "                         resnet_model.load_state_dict(new_state_dict, strict=False)\n",
    "                         print(\"Loaded ResNet state_dict with strict=False.\")\n",
    "                     except RuntimeError as e2:\n",
    "                         print(f\"Failed loading ResNet state_dict even with strict=False: {e2}\")\n",
    "                         resnet_model = None # Mark as failed\n",
    "\n",
    "            if resnet_model:\n",
    "                 # Validate output layer if possible (depends on model structure)\n",
    "                 if hasattr(resnet_model, 'fc') and resnet_model.fc.out_features != num_classes:\n",
    "                     print(f\"Warning: ResNet model FC layer units ({resnet_model.fc.out_features}) mismatch dataset classes ({num_classes}).\")\n",
    "                 resnet_model.eval()\n",
    "                 print(f\"ResNet model loaded from {resnet_model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or instantiating ResNet model from {resnet_model_path}: {e}\")\n",
    "            resnet_model = None\n",
    "    else:\n",
    "        print(f\"ResNet model file not found: {resnet_model_path}\")\n",
    "\n",
    "    # Load PyTorch model (ViT)\n",
    "    vit_model_path = \"vit_model.pth\"\n",
    "    vit_model = None\n",
    "    if os.path.exists(vit_model_path):\n",
    "        try:\n",
    "            checkpoint_vit = torch.load(vit_model_path, map_location=device)\n",
    "            if isinstance(checkpoint_vit, dict):\n",
    "                state_dict_vit = checkpoint_vit.get(\"model_state_dict\", checkpoint_vit)\n",
    "                if timm is not None:\n",
    "                    print(\"Loading ViT state_dict using timm...\")\n",
    "                    vit_model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=num_classes) # Use derived num_classes\n",
    "                    state_dict_vit = {k.replace(\"model.\", \"\"): v for k, v in state_dict_vit.items()}\n",
    "                    # Load state_dict, consider strict=False\n",
    "                    try:\n",
    "                         vit_model.load_state_dict(state_dict_vit, strict=True)\n",
    "                         vit_model.to(device)\n",
    "                    except RuntimeError as e:\n",
    "                         print(f\"Error loading ViT state_dict (likely mismatch): {e}. Trying strict=False.\")\n",
    "                         try:\n",
    "                             vit_model.load_state_dict(state_dict_vit, strict=False)\n",
    "                             vit_model.to(device)\n",
    "                             print(\"Loaded ViT state_dict with strict=False.\")\n",
    "                         except RuntimeError as e2:\n",
    "                             print(f\"Failed loading ViT state_dict even with strict=False: {e2}\")\n",
    "                             vit_model = None # Mark as failed\n",
    "                else:\n",
    "                    print(\"timm library not available, cannot load ViT state_dict automatically.\")\n",
    "                    vit_model = None\n",
    "            else:\n",
    "                 print(\"Loading saved ViT model object...\")\n",
    "                 vit_model = checkpoint_vit.to(device) # Assumes saved model object is compatible\n",
    "\n",
    "            if vit_model:\n",
    "                 # Validate output layer if possible (depends on timm model structure)\n",
    "                 if hasattr(vit_model, 'head') and hasattr(vit_model.head, 'out_features') and vit_model.head.out_features != num_classes:\n",
    "                      print(f\"Warning: ViT model head layer units ({vit_model.head.out_features}) mismatch dataset classes ({num_classes}).\")\n",
    "                 vit_model.eval()\n",
    "                 print(f\"ViT model loaded from {vit_model_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading ViT model from {vit_model_path}: {e}\")\n",
    "            vit_model = None\n",
    "    else:\n",
    "        print(f\"ViT model file not found: {vit_model_path}\")\n",
    "\n",
    "    # Check if at least one model loaded\n",
    "    if not keras_model and not resnet_model and not vit_model:\n",
    "        print(\"No models were loaded successfully. Cannot generate confusion matrices.\")\n",
    "        return\n",
    "\n",
    "    # Define image transformations\n",
    "    resnet_transform = transforms.Compose([\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.Resize((56,56)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "\n",
    "    vit_transform = transforms.Compose([\n",
    "        transforms.Resize((56,56)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "\n",
    "    # Initialize confusion matrices including the new ensemble\n",
    "    confusion_matrices = {\n",
    "        'VGG16': np.zeros((num_classes, num_classes), dtype=int),\n",
    "        'ResNet': np.zeros((num_classes, num_classes), dtype=int),\n",
    "        'ViT': np.zeros((num_classes, num_classes), dtype=int),\n",
    "        'ConfidenceEnsemble': np.zeros((num_classes, num_classes), dtype=int),\n",
    "        'ConfidenceEnsemble_NoViT': np.zeros((num_classes, num_classes), dtype=int), # New ensemble\n",
    "        'EnsembleA': np.zeros((num_classes, num_classes), dtype=int),\n",
    "        'EnsembleB': np.zeros((num_classes, num_classes), dtype=int),\n",
    "        'EnsembleC': np.zeros((num_classes, num_classes), dtype=int),\n",
    "        'EnsembleD': np.zeros((num_classes, num_classes), dtype=int),\n",
    "        'EnsembleE': np.zeros((num_classes, num_classes), dtype=int)\n",
    "    }\n",
    "\n",
    "    # Process each selected image\n",
    "    print(\"Generating predictions and updating confusion matrices...\")\n",
    "    for path, true_label in tqdm(zip(selected_paths, selected_labels), total=len(selected_paths), desc=\"Evaluating Images\"):\n",
    "        try:\n",
    "            true_idx = class_names.index(true_label)\n",
    "            img_binarized = binarize_image(path, target_size=(56, 56))\n",
    "\n",
    "            # Store predictions from each model for ensemble calculation\n",
    "            model_top1_predictions = {}\n",
    "            keras_preds_list = []\n",
    "            resnet_preds_list = []\n",
    "            vit_preds_list = []\n",
    "\n",
    "            # Keras (VGG16) predictions\n",
    "            if keras_model:\n",
    "                try:\n",
    "                    keras_preds_list = predict_top_n_keras(keras_model, img_binarized, class_names, top_n=3)\n",
    "                    if keras_preds_list:\n",
    "                        top1_pred_class = keras_preds_list[0][0]\n",
    "                        model_top1_predictions['VGG16'] = top1_pred_class\n",
    "                        # Update individual model confusion matrix if prediction is valid class name\n",
    "                        if top1_pred_class in class_names:\n",
    "                           pred_idx = class_names.index(top1_pred_class)\n",
    "                           confusion_matrices['VGG16'][true_idx, pred_idx] += 1\n",
    "                        else: print(f\"Warning: Keras predicted '{top1_pred_class}' not in class_names.\")\n",
    "                    else: model_top1_predictions['VGG16'] = None\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError during Keras prediction for {path}: {e}\")\n",
    "                    model_top1_predictions['VGG16'] = None\n",
    "\n",
    "            # ResNet predictions\n",
    "            if resnet_model:\n",
    "                try:\n",
    "                    img_for_resnet = img_binarized.convert(\"L\")\n",
    "                    resnet_preds_list = predict_top_n_torch(resnet_model, resnet_transform, img_for_resnet, class_names, device, top_n=3)\n",
    "                    if resnet_preds_list:\n",
    "                        top1_pred_class = resnet_preds_list[0][0]\n",
    "                        model_top1_predictions['ResNet'] = top1_pred_class\n",
    "                        # Update individual model confusion matrix\n",
    "                        if top1_pred_class in class_names:\n",
    "                             pred_idx = class_names.index(top1_pred_class)\n",
    "                             confusion_matrices['ResNet'][true_idx, pred_idx] += 1\n",
    "                        else: print(f\"Warning: ResNet predicted '{top1_pred_class}' not in class_names.\")\n",
    "                    else: model_top1_predictions['ResNet'] = None\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError during ResNet prediction for {path}: {e}\")\n",
    "                    model_top1_predictions['ResNet'] = None\n",
    "\n",
    "            # ViT predictions\n",
    "            if vit_model:\n",
    "                try:\n",
    "                    vit_preds_list = predict_top_n_torch(vit_model, vit_transform, img_binarized, class_names, device, top_n=3)\n",
    "                    if vit_preds_list:\n",
    "                        top1_pred_class = vit_preds_list[0][0]\n",
    "                        model_top1_predictions['ViT'] = top1_pred_class\n",
    "                         # Update individual model confusion matrix\n",
    "                        if top1_pred_class in class_names:\n",
    "                             pred_idx = class_names.index(top1_pred_class)\n",
    "                             confusion_matrices['ViT'][true_idx, pred_idx] += 1\n",
    "                        else: print(f\"Warning: ViT predicted '{top1_pred_class}' not in class_names.\")\n",
    "                    else: model_top1_predictions['ViT'] = None\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError during ViT prediction for {path}: {e}\")\n",
    "                    model_top1_predictions['ViT'] = None\n",
    "\n",
    "            # Calculate Confidence-weighted ensemble predictions (Original and NoViT)\n",
    "            confidence_sums = defaultdict(float)\n",
    "            confidence_sums_no_vit = defaultdict(float)\n",
    "\n",
    "            # Accumulate probabilities from Keras predictions\n",
    "            for cls, prob in keras_preds_list:\n",
    "                 # Ensure class is valid before adding\n",
    "                 if cls in class_names:\n",
    "                      confidence_sums[cls] += prob\n",
    "                      confidence_sums_no_vit[cls] += prob\n",
    "\n",
    "            # Accumulate probabilities from ResNet predictions\n",
    "            for cls, prob in resnet_preds_list:\n",
    "                  if cls in class_names:\n",
    "                       confidence_sums[cls] += prob\n",
    "                       confidence_sums_no_vit[cls] += prob\n",
    "\n",
    "            # Accumulate probabilities from ViT predictions (only for the original ensemble)\n",
    "            for cls, prob in vit_preds_list:\n",
    "                  if cls in class_names:\n",
    "                       confidence_sums[cls] += prob\n",
    "\n",
    "            # Determine final prediction for ConfidenceEnsemble\n",
    "            if confidence_sums:\n",
    "                confidence_pred_class = max(confidence_sums, key=confidence_sums.get)\n",
    "                pred_idx = class_names.index(confidence_pred_class)\n",
    "                confusion_matrices['ConfidenceEnsemble'][true_idx, pred_idx] += 1\n",
    "\n",
    "            # Determine final prediction for ConfidenceEnsemble_NoViT\n",
    "            if confidence_sums_no_vit:\n",
    "                confidence_no_vit_pred_class = max(confidence_sums_no_vit, key=confidence_sums_no_vit.get)\n",
    "                pred_idx = class_names.index(confidence_no_vit_pred_class)\n",
    "                confusion_matrices['ConfidenceEnsemble_NoViT'][true_idx, pred_idx] += 1\n",
    "\n",
    "\n",
    "            # Calculate predictions for weighted ensembles (A, B, C, D, E) using top-1 predictions\n",
    "            for ensemble_name, weights in ENSEMBLE_WEIGHTS.items():\n",
    "                ensemble_scores = defaultdict(float)\n",
    "                for model_name, top1_class in model_top1_predictions.items():\n",
    "                    # Check if prediction exists, is a valid class, and has weight in this ensemble\n",
    "                    if top1_class is not None and top1_class in class_names and model_name in weights:\n",
    "                        ensemble_scores[top1_class] += weights.get(model_name, 0.0) # Use get for safety\n",
    "\n",
    "                if ensemble_scores:\n",
    "                    weighted_pred_class = max(ensemble_scores, key=ensemble_scores.get)\n",
    "                    pred_idx = class_names.index(weighted_pred_class)\n",
    "                    confusion_matrices[ensemble_name][true_idx, pred_idx] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing image {path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Create output subfolder if it doesn't exist\n",
    "    output_dir = OUTPUT_SUBFOLDER\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"\\nSaving confusion matrices to subfolder: {output_dir}\")\n",
    "\n",
    "    # Save confusion matrices to CSV files inside the subfolder\n",
    "    active_models_and_ensembles = ['VGG16', 'ResNet', 'ViT', 'ConfidenceEnsemble', 'ConfidenceEnsemble_NoViT'] + list(ENSEMBLE_WEIGHTS.keys()) # Added new ensemble\n",
    "\n",
    "    for name in active_models_and_ensembles:\n",
    "        should_save = False\n",
    "        # Determine if the matrix should be saved based on model availability or if it's an ensemble\n",
    "        if name == 'VGG16' and keras_model: should_save = True\n",
    "        elif name == 'ResNet' and resnet_model: should_save = True\n",
    "        elif name == 'ViT' and vit_model: should_save = True\n",
    "        elif name.startswith('Ensemble') or name.startswith('ConfidenceEnsemble'): # Cover all ensemble types\n",
    "             # Ensembles should be saved if at least one contributing model loaded\n",
    "             if name == 'ConfidenceEnsemble_NoViT':\n",
    "                 should_save = bool(keras_model or resnet_model)\n",
    "             elif name == 'EnsembleC': # VGG+ResNet\n",
    "                 should_save = bool(keras_model or resnet_model)\n",
    "             elif name == 'EnsembleD': # ResNet+ViT\n",
    "                 should_save = bool(resnet_model or vit_model)\n",
    "             elif name == 'EnsembleE': # VGG+ViT\n",
    "                 should_save = bool(keras_model or vit_model)\n",
    "             else: # ConfidenceEnsemble, EnsembleA, EnsembleB assume all models might contribute\n",
    "                 should_save = bool(keras_model or resnet_model or vit_model)\n",
    "\n",
    "\n",
    "        if should_save and name in confusion_matrices:\n",
    "            matrix = confusion_matrices[name]\n",
    "            # Only save if the matrix contains counts (i.e., predictions were made)\n",
    "            if matrix.sum() > 0:\n",
    "                df = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "                output_filename = f'confusion_{name}.csv'\n",
    "                output_path = os.path.join(output_dir, output_filename)\n",
    "                try:\n",
    "                    df.to_csv(output_path)\n",
    "                    print(f\"Saved confusion matrix to {output_path}\")\n",
    "                except IOError as e:\n",
    "                    print(f\"Error saving confusion matrix {output_filename} to CSV: {e}\")\n",
    "            else:\n",
    "                 print(f\"Skipping saving empty confusion matrix for {name} (no predictions recorded).\")\n",
    "        elif name in confusion_matrices: # Matrix exists but shouldn't be saved (e.g., model not loaded)\n",
    "             print(f\"Skipping saving confusion matrix for {name} (required model(s) not loaded or no predictions made).\")\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        evaluate_models_confusion_matrix()\n",
    "        print(\"\\nScript finished.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\nError: {e}. Please ensure dataset directories and model files exist.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError: {e}. Please check dataset structure or configuration.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
